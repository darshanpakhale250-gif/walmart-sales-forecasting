# -*- coding: utf-8 -*-
"""Walmart_Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DL6Uuc8jSqGwy6s1wCLRn91P3fkauG2D
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv('/content/Walmart DataSet.csv')
df

df.isnull().sum().sum()

df.duplicated().sum()

df.info()

df.shape

df.head()

df['Date'] = pd.to_datetime(df['Date'], format='%d-%m-%Y')
display(df.info())

plt.figure(figsize=(8,5))
sns.histplot(df['Weekly_Sales'], kde=True)
plt.title("Weekly Sales Distribution")
plt.show()

plt.figure(figsize=(8,5))
sns.scatterplot(x='Unemployment', y='Weekly_Sales', data=df, alpha=0.5)
plt.title("Weekly Sales vs Unemployment")
plt.show()

Q1 = df['Weekly_Sales'].quantile(0.25)
Q3 = df['Weekly_Sales'].quantile(0.75)
IQR = Q3 - Q1

outliers = df[(df['Weekly_Sales'] < Q1 - 1.5 * IQR) |
              (df['Weekly_Sales'] > Q3 + 1.5 * IQR)]

print(f"Number of outliers in Weekly Sales: {len(outliers)}")

corr = df['Weekly_Sales'].corr(df['Unemployment'])
print(f"Overall correlation: {corr:.2f}")

store_avg = df.groupby('Store').apply(
    lambda x: x['Weekly_Sales'].corr(x['Unemployment'])
).reset_index(name='Sales_Unemp_Corr')

store_avg = store_avg.sort_values('Sales_Unemp_Corr')
print("\nStores most negatively affected by Unemployment:")
print(store_avg.head())

top_affected = store_avg.head(5)
plt.figure(figsize=(8,5))
sns.barplot(x='Store', y='Sales_Unemp_Corr', data=top_affected)
plt.title("Top 5 Stores Most Negatively Affected by Unemployment")
plt.ylabel("Correlation")
plt.show()

overall_corr = df['Weekly_Sales'].corr(df['Unemployment'])

if overall_corr < 0:
    print(f" higher unemployment is linked to LOWER weekly sales (corr = {overall_corr:.2f}).")
elif overall_corr > 0:
    print(f" higher unemployment is linked to HIGHER weekly sales (corr = {overall_corr:.2f}).")
else:
    print(f"No clear overall correlation between unemployment and sales (corr = {overall_corr:.2f}).")

worst_store = store_avg.iloc[0]
print(f"Store {worst_store['Store']} is most negatively affected (corr = {worst_store['Sales_Unemp_Corr']:.2f}).")

df = df.sort_values('Date')

plt.figure(figsize=(12,6))
sns.lineplot(x='Date', y='Weekly_Sales', data=df)
plt.title("Weekly Sales Over Time (Seasonal Trends)")
plt.show()

df.head()

# Temperature vs Weekly Sales correlation
temp_corr = df['Weekly_Sales'].corr(df['Temperature'])
print(f"Correlation between Temperature and Weekly Sales: {temp_corr:.2f}")

# Visualization
sns.scatterplot(x='Temperature', y='Weekly_Sales', data=df, alpha=0.5)
plt.title("Weekly Sales vs Temperature")
plt.show()

cpi_corr = df['Weekly_Sales'].corr(df['CPI'])
print(f"Overall correlation (CPI vs Weekly Sales): {cpi_corr:.2f}")

cpi_store_corr = df.groupby('Store').apply(
    lambda x: x['Weekly_Sales'].corr(x['CPI'])
).reset_index(name='CPI_Sales_Corr')

cpi_store_corr = cpi_store_corr.sort_values('CPI_Sales_Corr')
print("\nStores most negatively affected by CPI:")
print(cpi_store_corr.head())

top_cpi_affected = cpi_store_corr.head(5)
sns.barplot(x='Store', y='CPI_Sales_Corr', data=top_cpi_affected)
plt.title("Stores Most Negatively Affected by CPI")
plt.show()

store_avg_sales = df.groupby('Store')['Weekly_Sales'].mean().reset_index()

top_stores = store_avg_sales.sort_values('Weekly_Sales', ascending=False)

print("Top 5 Performing Stores:")
print(top_stores.head())

sns.barplot(x='Store', y='Weekly_Sales', data=top_stores.head(5))
plt.title("Top 5 Performing Stores (Average Weekly Sales)")
plt.ylabel("Avg Weekly Sales")
plt.show()

best_store = top_stores.iloc[0]
worst_store = top_stores.iloc[-1]

print(f"Best Store: {best_store['Store']} → Avg Weekly Sales = {best_store['Weekly_Sales']:.2f}")
print(f"Worst Store: {worst_store['Store']} → Avg Weekly Sales = {worst_store['Weekly_Sales']:.2f}")

difference = best_store['Weekly_Sales'] - worst_store['Weekly_Sales']
percent_diff = (difference / best_store['Weekly_Sales']) * 100

print(f"Difference in Sales: {difference:.2f}")
print(f"Percentage Difference: {percent_diff:.2f}%")

from statsmodels.tsa.arima.model import ARIMA

df = df.sort_values(['Store', 'Date'])

forecasts = []

for store_id in df['Store'].unique():
    store_data = df[df['Store'] == store_id].set_index('Date')['Weekly_Sales']

    try:
        model = ARIMA(store_data, order=(1,1,1))
        model_fit = model.fit()

        forecast = model_fit.forecast(steps=12)

        for date, pred in zip(pd.date_range(store_data.index[-1] + pd.Timedelta(weeks=1), periods=12, freq='W'), forecast):
            forecasts.append({'Store': store_id, 'Date': date, 'Predicted_Weekly_Sales': pred})

    except Exception as e:
        print(f"Store {store_id}: Model failed - {e}")

# Convert to DataFrame
forecast_df = pd.DataFrame(forecasts)
print(forecast_df.head())

# Plot example for one store
sample_store = df['Store'].unique()[0]
plt.figure(figsize=(10,5))
plt.plot(df[df['Store'] == sample_store]['Date'], df[df['Store'] == sample_store]['Weekly_Sales'], label='Historical')
plt.plot(forecast_df[forecast_df['Store'] == sample_store]['Date'],
         forecast_df[forecast_df['Store'] == sample_store]['Predicted_Weekly_Sales'], label='Forecast', color='red')
plt.title(f"Store {sample_store} - Sales Forecast (Next 12 Weeks)")
plt.legend()
plt.show()

df['Date'] = pd.to_datetime(df['Date'], format='%d-%m-%Y')
df_time_series = df.groupby(['Store', 'Date'])['Weekly_Sales'].sum().reset_index()
df_time_series = df_time_series.sort_values(['Store', 'Date'])
display(df_time_series.head())